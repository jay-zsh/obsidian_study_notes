# 38.7 总结

**压缩模型 #1：基于比特的算法操作。** 给定一个比特序列 B，我们将其通过压缩算法 C 形成新的比特流 C(B)。我们可以将 C(B) 通过相应的解压缩算法来恢复 B。理想情况下，C(B) 小于 B。

---

**变长码字。** 基本思想：使用变长码字表示符号，较短的码字分配给更常见的符号。例如，与其用 8 位 ASCII 值表示每个英文字符，我们可以用更短的序列表示更常见的值。摩尔斯电码就是一个变长码字系统的例子。

---

**前缀自由码。** 如果某些码字是其他码字的前缀，则会产生歧义，如摩尔斯电码所示。前缀自由码是一种码字，其中没有任何码字是其他码字的前缀。前缀自由码可以唯一解码。

---

**香农-范诺编码。** 香农-范诺编码是一种生成前缀自由码的直观过程。首先，统计所有符号的出现频率。然后，基于频率递归地将字符分成两半，每次分割时，为码字末尾附加 1 或 0。

---

**霍夫曼编码。** 霍夫曼编码生成一个可证明最优的前缀自由码，与可能次优的香农-范诺编码不同。首先，统计所有符号的出现频率，并为每个符号创建一个“节点”。然后，将频率最低的两个节点合并为一棵树，以新超节点为根，为码字开头附加 1 或 0。重复此过程，直到所有符号都成为树的一部分。生成的编码是最优的。

---

**霍夫曼实现。** 要压缩符号序列，我们统计频率、构建编码数组和解码字典树，将字典树写入输出，然后在编码数组中查找每个符号，并将相应的比特序列写入输出。要解压缩，我们读取字典树，然后重复使用最长前缀匹配来恢复原始符号。

---

**压缩背后的通用原则。** 霍夫曼编码的核心是用少量比特表示常见符号。还有其他思想，如游程编码（将每个字符替换为自身后跟其出现次数）和 LZW（在输入中搜索常见重复模式）。更一般地，目标是利用输入中的冗余和现有顺序。

---

**通用压缩是不可能的。** 不可能创建一种算法，能将任何比特流压缩 50%。否则，你可以反复压缩，直到只剩 1 比特，这显然是荒谬的。第二个论点是，对于大小为 1000 的输入比特流，根据鸽巢原理，只有 2^499 分之一的比特流能被压缩 50%。

---

**压缩模型 #2：自提取比特。** 将算法和输入比特流分开处理（如模型 #1）是更精确的模型，但它似乎允许奇怪算法，例如将期望输出硬编码到算法本身。例如，我们可能有一个 .java 解压缩算法，其中包含你最喜欢的电视节目的巨大 `byte[]` 数组，如果算法收到输入 `010`，它就输出这个 `byte[]` 数组。

换句话说，在考虑输出大小时，不仅包括压缩比特，还包括用于解压缩的算法，似乎更合理。

一个概念性技巧是想象我们的算法和比特本身是一个单一实体，可视为自提取比特序列。当输入解释器时，这个自提取比特序列生成特定输出序列。

---

**Hugplant 示例。** 如果我们有一个像讲座中 hugplant.bmp 的图像文件，可以将其分成 8 比特块，然后用霍夫曼编码压缩。如果我们将此文件交给他人，他们可能不知道如何解压缩，因为霍夫曼编码不是主流操作系统支持的标准压缩算法。因此，我们还需要提供霍夫曼解码算法。我们可以将其作为单独的 .java 文件发送，但为概念方便并符合压缩模型 #2，我们将想象已将压缩比特流打包到一个 .java 文件中的 `byte[]` 数组中。当传递给解释器时，这个比特流生成原始的 hugplant.bmp，其大小是压缩比特流 + 霍夫曼解释器的 4 倍。